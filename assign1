import pandas as pd
import numpy as np

dvz_handler=0.00000000000001

dataset = {'Taste': ['Salty', 'Spicy', 'Spicy', 'Spicy', 'Spicy', 'Sweet', 'Salty', 'Sweet', 'Spicy', 'Salty'],
           'Temperature': ['Hot', 'Hot', 'Hot', 'Cold', 'Hot', 'Cold', 'Cold', 'Hot', 'Cold', 'Hot'],
           'Texture': ['Soft', 'Soft', 'Hard', 'Hard', 'Hard', 'Soft', 'Soft', 'Soft', 'Soft', 'Hard'],
           'Eat': ['No', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes']}

df = pd.DataFrame(dataset, columns=['Taste', 'Temperature', 'Texture', 'Eat'])

# print (len(df), "fffffffffffffffffff")
# data = pd.read_csv('E:/43/ML_off/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')

# print(data.columns)

# print(data.shape)

entropy_node = 0  # Initialize Entropy
values = df.Eat.unique()
# print(values)
# print(df.Eat.value_counts()['No'])
for value in values:
    fraction = df.Eat.value_counts()[value] / len(df.Eat)
    entropy_node += -fraction * np.log2(fraction)
# print(entropy_node)

#print(df.keys()[-1])


# entropy ber korar jonno function lihtesi ekta..pandas e dataframe ar feature er naam pathaile oitar jonno entropy diye dibe
def entropy_attribute(data, feature):
    decision_feature=data.keys()[-1]
    decision_types=data[decision_feature].unique()

    feature_types=data[feature].unique()

    entropy = 0
    for f_t in feature_types:
        e_temp=0
        for d_t in decision_types:
            e_temp_num=len(data[feature][data[feature]==f_t][data[decision_feature]==d_t])
            e_temp_den=len(data[feature][data[feature]==f_t])
            e_temp+=-(e_temp_num/(e_temp_den+dvz_handler))*np.log2((e_temp_num/(e_temp_den))+dvz_handler)
            # print("e_temp_num", e_temp_num)
            # print("e_temp_den", e_temp_den)
            # print(e_temp)

        entropy+=(e_temp_den/len(data))*e_temp
    # print(feature_types)
    return entropy

# print(entropy_attribute(df, 'Taste'))

def entropy_dataset(data):
    decision_feature = data.keys()[-1]
    entropy = 0
    decision_types = df[decision_feature].unique()
    for d_t in decision_types:
        fraction = df[decision_feature].value_counts()[d_t] / len(df[decision_feature])
        entropy += -fraction * np.log2(fraction)
    return entropy


def max_information_gain(data):
    #Entropy_att = []
    keys = data.keys()[:-1]
    entropy_data = entropy_dataset(data)
    print(entropy_data)
    IG = []
    for key in keys:
        IG.append(entropy_data-entropy_attribute(data,key))
        print(IG)
    print(keys[np.argmax(IG)])


def get_subtable(df, node, val):
    return df[df[node] == val].reset_index(drop=True)


def buildTree(df, tree=None):
    decision_feature = df.keys()[-1]
    node = max_information_gain(df)

    print(node)

    feature_types = np.unique(df[node])

    # Create an empty dictionary to create tree
    if tree is None:
        tree = {}
        tree[node] = {}

    # We make loop to construct a tree by calling this function recursively.
    # In this we check if the subset is pure and stops if it is pure.

    for f_t in feature_types:

        subtable = get_subtable(df, node, f_t)
        clValue, counts = np.unique(subtable['Eat'], return_counts=True)

        if len(counts) == 1:  # Checking purity of subset
            tree[node][value] = clValue[0]
        else:
            tree[node][value] = buildTree(subtable)  # Calling the function recursively

    return tree


tree = buildTree(df)
print(tree)